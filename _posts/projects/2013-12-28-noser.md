---
layout: video
subheadline: "New Interface for Musical Expression"
title:  "Noser"
teaser: "Noser is a musical instrument for exploring vocal resonance with the hand. It was developed and performed for the New Interfaces for Musical Expression (NIME) course at ITP."
breadcrumb: false
categories:
    - projects
tags:
    - blog
    - content
    - post
    - post format

image:
    title: "Noser"
    thumb: noser_small_2.png

author: Andy Sigler

header: no

iframe: "<iframe width='970' height='546' src='//player.vimeo.com/video/85275765' frameborder='0' allowfullscreen></iframe>"

---

Noser is a combination of musical instruments, exploring the real-time performance of timbre. Traditional instrumentation has explored changes in pitch, level, rhythm and timing for thousands of years. With computers and music synthesis, we can now explore the manipulation of a sound's spectral shape and content through physical interaction. For my methods, I first used the combination of FFT convolution and the Touche sensing technique, and second, resonant filters modeling the human vocal tract. Convolution and vowel modeling, combined with physical interaction with the hands, has led to some interesting results.

Below is an earlier prototype of the system.

<iframe src="https://player.vimeo.com/video/74424188" width="500" height="278" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen markdown="1"></iframe>

This interface uses a multi-touch trackpad, proximity sensor, and flexible polycarbonite poles, all to allow the human hand to expressively perform vowel sounds. The fingers horizontal position moves the frequency of resonant bandpass filters, while their vertical position alters the filters' Q.
